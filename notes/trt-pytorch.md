# ä½¿ç”¨TensorRT5åŠ é€Ÿpytorchæ¨¡å‹æ ‡å‡†æµ‹è¯•
## TREE
* ä¸€ã€ä¸»æœºç¯å¢ƒ   
* äºŒã€ä¸»æœºç¯å¢ƒæµ‹è¯•
* ä¸‰ã€Dockerç¯å¢ƒæµ‹è¯•  
## ä¸€ã€ä¸»æœºç¯å¢ƒ  
* CPU  
```
cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 
20  Genuine Intel(R) CPU @ 2.40GHz
```
* Memory   
```
free -h
              total        used        free      shared  buff/cache   available
Mem:            31G        652M         19G         77M         11G         30G
Swap:          975M        192M        783M
æˆ–è€…cat /proc/meminfo
```
* GPU   
```
nvidia-smi
Fri May 24 13:31:05 2019       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 410.79       Driver Version: 410.79       CUDA Version: 10.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla P40           Off  | 00000000:03:00.0 Off |                  Off |
| N/A   41C    P0    45W / 250W |      0MiB / 24451MiB |      3%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```
* OS   
``` 
head -n 1 /etc/issue
Ubuntu 16.04.5 LTS \n \l
```
* Kernal   
``` 
uname -a
Linux ubuntu 4.4.0-131-generic #157-Ubuntu SMP Thu Jul 12 15:51:36 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
```
* [CUDA 10.0.x](https://github.com/fusimeng/ParallelComputing/blob/master/notes/cudainstall.md)   
```   
cat /usr/local/cuda/version.txt
CUDA Version 10.0.130

nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2018 NVIDIA Corporation
Built on Sat_Aug_25_21:08:01_CDT_2018
Cuda compilation tools, release 10.0, V10.0.130
```
* [cuDNN 7.5.x](https://github.com/fusimeng/ParallelComputing/blob/master/notes/cudainstall.md)   
``` 
cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2
#define CUDNN_MAJOR 7
#define CUDNN_MINOR 5
#define CUDNN_PATCHLEVEL 0
--
#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)
#include "driver_types.h"
```
* [Docker](https://github.com/fusimeng/ParallelComputing/blob/master/notes/docker.md)
* [Nvidia-Docker](https://github.com/fusimeng/ParallelComputing/blob/master/notes/nvdocker.md)   
## äºŒã€ä¸»æœºç¯å¢ƒæµ‹è¯•
### 1.ä¸»æœºç¯å¢ƒå‡†å¤‡
#### ï¼ˆ1ï¼‰.å®‰è£…Anaconda
å‚è€ƒé“¾æ¥ï¼š[ğŸ”—](https://github.com/fusimeng/ai_tools)    
#### ï¼ˆ2ï¼‰. ä½¿ç”¨Anacondaï¼Œåˆ›å»ºæ‰€éœ€çš„ç¯å¢ƒ   
```shell
conda create --name pytorch python=3.6
source activate pytorch
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple torch torchvision tensorboardx
```
```
pip list 
Package      Version 
------------ --------
certifi      2019.3.9
cffi         1.12.3  
mkl-fft      1.0.12  
mkl-random   1.0.2   
numpy        1.16.3  
olefile      0.46    
Pillow       6.0.0   
pip          19.1    
protobuf     3.7.1   
pycparser    2.19    
setuptools   41.0.1  
six          1.12.0  
tensorboardX 1.6     
torch        1.0.1   
torchvision  0.2.1   
wheel        0.33.1
```
#### (3) å®‰è£…tensorrt   
å‚è€ƒé“¾æ¥ï¼š[ğŸ”—](https://github.com/fusimeng/TensorRT/blob/master/notes/install.md)   
#### (4) å®‰è£…opencv(å¯é€‰ï¼Œä»£ç éœ€è¦åœ¨å®‰è£…ï¼‰   
å‚è€ƒé“¾æ¥ï¼š[ğŸ”—](https://github.com/fusimeng/ParallelComputing/blob/master/notes/dockerai-2.md#2-%E4%B8%8B%E8%BD%BDopencv-410)   

### 2.æ•°æ®å‡†å¤‡
ä¸‹è½½[mnistæ•°æ®é›†](http://yann.lecun.com/exdb/mnist/)æ•°æ®é›†ï¼Œæ”¾åœ¨dataç›®å½•ä¸‹ã€‚   
### 3.æ ‡å‡†ä»£ç æµ‹è¯•-1
#### ï¼ˆ1ï¼‰ ä»£ç å‡†å¤‡       
``` 
-tensorrt   
--test.py
```
#### ï¼ˆ2ï¼‰.æµ‹è¯•
**ç”¨æ³•**ï¼š   
```shell
python test.py 
```

### 5. pytorchæŒ‡å®šæ˜¾å¡çš„å‡ ç§æ–¹å¼   
1.ç›´æ¥ç»ˆç«¯ä¸­è®¾å®šï¼š   
```
CUDA_VISIBLE_DEVICES=1 python my_script.py
```
2.pythonä»£ç ä¸­è®¾å®šï¼š   
```
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "2"
```
3.ä½¿ç”¨å‡½æ•° set_device
```
import torch
torch.cuda.set_device(id)
```
## ä¸‰ã€Dockerç¯å¢ƒæµ‹è¯•
### 1.Dockerç¯å¢ƒå‡†å¤‡
é•œåƒï¼šfusimeng/ai-pytorch:16.04-10.0-3.5-1.1.0   
### 2.æ•°æ®å‡†å¤‡
åŒä¸Š
### 3.ä»£ç å‡†å¤‡
åŒä¸Š
### 4.æµ‹è¯•
åŒä¸Š

é€šè¿‡pytorchæ­å»ºå·ç§¯ç¥ç»ç½‘ç»œå®Œæˆæ‰‹å†™è¯†åˆ«ä»»åŠ¡ï¼Œå¹¶å°†è®­ç»ƒå¥½çš„æ¨¡å‹ä»¥å¤šç§æ–¹å¼éƒ¨ç½²åˆ°TensorRTä¸­åŠ é€Ÿã€‚

#




### 2.æ•°æ®å‡†å¤‡

### 3.ä»£ç å‡†å¤‡       
``` 
-tensorrt 
--Config.pyï¼šå·ç§¯ç¥ç»ç½‘ç»œé…ç½®å‚æ•°
--DataLoader.pyï¼šè¯»å–è®­ç»ƒé›†ä¸æµ‹è¯•é›†
--Network.pyï¼šå·ç§¯ç¥ç»ç½‘ç»œç»“æ„
--OperateNetwork.pyï¼šå¯¹å·ç§¯ç¥ç»ç½‘ç»œçš„æ“ä½œï¼ˆè®­ç»ƒï¼Œæµ‹è¯•ï¼Œä¿å­˜è¯»å–æƒé‡ï¼Œä¿å­˜onnxï¼‰
--TensorRTNet.pyï¼šä¸‰ç§æ–¹å¼åˆ›å»ºå¼•æ“
--main.pyï¼šä¸»å‡½æ•°
```
```
æ³¨æ„ï¼š
(1)å¯¹äºå¤šè¾“å…¥æ¨¡å‹ä¿å­˜onnxçš„æ–¹å¼ï¼š
dummy_input0 = torch.FloatTensor(Batch_size, seg_length).to(torch.device("cuda"))  
dummy_input1 = torch.FloatTensor(Batch_size, seg_length).to(torch.device("cuda"))  
dummy_input2 = torch.FloatTensor(Batch_size, seg_length).to(torch.device("cuda"))  
torch.onnx.export(model. (dummy_input0, dummy_input1, dummy_input2), filepath)  
(2)TensorRTä¸æ”¯æŒint64ï¼Œfloat64,å› æ­¤æ¨¡å‹ä¸åº”è¯¥åŒ…å«è¿™ä¸¤ç§æ•°æ®ç±»å‹çš„è¿ç®—ã€‚
```
### 4.æµ‹è¯•åŠç»“æœåˆ†æ
**ç”¨æ³•**ï¼š   
```shell
python smsg.py --lr 0.001 --epoch 1 --trainBatchSize 10000 --testBatchSize 10000 --num_workers 2 --log "../output/" 

optional arguments:   

--lr                default=1e-3    learning rate
--epoch             default=10     number of epochs tp train for
--trainBatchSize    default=100     training batch size
--testBatchSize     default=100     test batch size
--cuda              default=torch.cuda.is_available()  whether cuda is in use
--log               default="../output/"    storage logs/models
--num_workers       default=4, type=int,    number of workers to load data
--resume            default="../output/"    resume model 
å¤‡æ³¨ï¼š æ¨¡å‹åŠ è½½ï¼Œå†æ¬¡è®­ç»ƒè¿™ä¸ªåŠŸèƒ½æ²¡æœ‰åš
```
**pytorchæŒ‡å®šæ˜¾å¡çš„å‡ ç§æ–¹å¼**   
1.ç›´æ¥ç»ˆç«¯ä¸­è®¾å®šï¼š   
```
CUDA_VISIBLE_DEVICES=1 python my_script.py
```
2.pythonä»£ç ä¸­è®¾å®šï¼š   
```
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "2"
```
3.ä½¿ç”¨å‡½æ•° set_device
```
import torch
torch.cuda.set_device(id)
```
## äºŒã€Dockerç¯å¢ƒ
### 1.ç¯å¢ƒå‡†å¤‡
é•œåƒï¼šhttps://cloud.docker.com/repository/docker/fusimeng/ai.pytorch    
ä½¿ç”¨é•œåƒï¼šfusimeng/ai.pytorch:v5   
### 2.æ•°æ®å‡†å¤‡
åŒä¸Š
### 3.ä»£ç å‡†å¤‡
åŒä¸Š
### 4.æµ‹è¯•åŠç»“æœåˆ†æ
```shell
nvidia-docker run -itd -v /root/felix/:/workspace fusimeng/ai.pytorch:v5
nvidia-docker exec -it xxx bash
```
**ä»£ç ç”¨æ³•**ï¼š   
åŒä¸Š
## Reference
[1] https://github.com/GuanLianzheng/pytorch_to_TensorRT5