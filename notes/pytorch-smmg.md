# Pytorchå•æœºå¤šå¡æ ‡å‡†æµ‹è¯•   
## TREE
* ä¸€ã€ä¸»æœºç¯å¢ƒ   
* äºŒã€ä¸»æœºç¯å¢ƒæµ‹è¯•
* ä¸‰ã€Dockerç¯å¢ƒæµ‹è¯•  
## ä¸€ã€ä¸»æœºç¯å¢ƒ  
* CPU  
```
cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 
20  Genuine Intel(R) CPU @ 2.40GHz
```
* Memory   
```
free -h
              total        used        free      shared  buff/cache   available
Mem:            31G        652M         19G         77M         11G         30G
Swap:          975M        192M        783M
æˆ–è€…cat /proc/meminfo
```
* GPU   
```
nvidia-smi
Wed May  8 21:38:46 2019       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.183      Driver Version: 384.183      CUDA Version: 9.0      |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |
| N/A   37C    P0    41W / 300W |     10MiB / 32502MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |
| N/A   39C    P0    43W / 300W |     10MiB / 32502MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |
| N/A   39C    P0    44W / 300W |     10MiB / 32502MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |
| N/A   37C    P0    45W / 300W |     10MiB / 32502MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |
| N/A   37C    P0    42W / 300W |     10MiB / 32502MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |
| N/A   38C    P0    43W / 300W |     10MiB / 32502MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |
| N/A   38C    P0    43W / 300W |     10MiB / 32502MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |
| N/A   37C    P0    42W / 300W |     10MiB / 32502MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```
* OS   
``` 
head -n 1 /etc/issue
Ubuntu 16.04.5 LTS \n \l
```
* Kernal   
``` 
uname -a
Linux ubuntu 4.4.0-131-generic #157-Ubuntu SMP Thu Jul 12 15:51:36 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
```
* [CUDA 10.0.x](https://github.com/fusimeng/ParallelComputing/blob/master/notes/cudainstall.md)   
```   
cat /usr/local/cuda/version.txt
CUDA Version 10.0.130

nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2018 NVIDIA Corporation
Built on Sat_Aug_25_21:08:01_CDT_2018
Cuda compilation tools, release 10.0, V10.0.130
```
* [cuDNN 7.5.x](https://github.com/fusimeng/ParallelComputing/blob/master/notes/cudainstall.md)   
``` 
cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2
#define CUDNN_MAJOR 7
#define CUDNN_MINOR 5
#define CUDNN_PATCHLEVEL 0
--
#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)
#include "driver_types.h"
```
* [Docker](https://github.com/fusimeng/ParallelComputing/blob/master/notes/docker.md)
* [Nvidia-Docker](https://github.com/fusimeng/ParallelComputing/blob/master/notes/nvdocker.md)   
## äºŒã€ä¸»æœºç¯å¢ƒæµ‹è¯•
### 1.ä¸»æœºç¯å¢ƒå‡†å¤‡
#### ï¼ˆ1ï¼‰.å®‰è£…Anaconda
å‚è€ƒé“¾æ¥ï¼š[ğŸ”—](https://github.com/fusimeng/ai_tools)    
#### ï¼ˆ2ï¼‰. ä½¿ç”¨Anacondaï¼Œåˆ›å»ºæ‰€éœ€çš„ç¯å¢ƒ   
```shell
conda create --name pytorch python=3.6
source activate pytorch
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple torch torchvision tensorboardx
```
```
pip list 
Package      Version 
------------ --------
certifi      2019.3.9
cffi         1.12.3  
mkl-fft      1.0.12  
mkl-random   1.0.2   
numpy        1.16.3  
olefile      0.46    
Pillow       6.0.0   
pip          19.1    
protobuf     3.7.1   
pycparser    2.19    
setuptools   41.0.1  
six          1.12.0  
tensorboardX 1.6     
torch        1.0.1   
torchvision  0.2.1   
wheel        0.33.1
```
### 2.æ•°æ®å‡†å¤‡
ä¸‹è½½[cifar-10-python.tar.gz](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)æ•°æ®é›†ï¼Œæ”¾åœ¨dataç›®å½•ä¸‹ã€‚   
**cifar10ä»‹ç»**    
The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.

The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.

(1) [å®‰è£…Anaconda](https://github.com/fusimeng/ai_tools)    
(2) ä½¿ç”¨Anacondaï¼Œåˆ›å»ºæ‰€éœ€çš„ç¯å¢ƒ   
* python3.6
* numpy
* pytorch 1.0.0
* torchvision 0.2.1
```shell
conda create --name pytorch python=3.6
source activate pytorch
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pytorch torchvision tensorboardx
```
```shell
pip list 
Package     Version 
----------- --------
certifi     2019.3.9
cffi        1.12.3  
mkl-fft     1.0.12  
mkl-random  1.0.2   
numpy       1.16.3  
olefile     0.46    
Pillow      6.0.0   
pip         19.1    
pycparser   2.19    
setuptools  41.0.1  
six         1.12.0  
torch       1.0.1   
torchvision 0.2.1   
wheel       0.33.1 
```
### 3.ä»£ç å‡†å¤‡     
``` 
-pytorch  # pytorchæ ‡å‡†æµ‹è¯•ä»£ç ç›®å½• 
--models  # æ¨¡å‹ç›®å½•
----AlexNet.py
----DenseNet.py
----GoogleNet.py
----LeNet.py
----ResNet.py
----VGG.py
----WideResNet.py
--smmg.py # æµ‹è¯•ä¸»ç¨‹åº
--smmg_dist.py # æµ‹è¯•ä¸»ç¨‹åº
--until.py # æ˜¾å¼åº“
```
 
### 4.æµ‹è¯•
#### (1) ç”¨æ³•-1   
```shell
python smmg.py   
smmg.py ä½¿ç”¨torch.nn.DataParallelæ–¹æ³•è¿›è¡Œæ•°æ®åˆ†å¸ƒå¼ã€‚ 
```  
**å‚æ•°è¯´æ˜ï¼š**   
```
--lr,               default=0.001, type=float, help='learning rate'
--epoch,            default=10, type=int, help='number of epochs tp train for'
--trainBatchSize,   default=1000, type=int, help='training batch size'
--testBatchSize,    default=1000, type=int, help='testing batch size'
--cuda,             default=torch.cuda.is_available(), type=bool, help='whether cuda is in use'
--log,              default="../output/smmg.pkl", type=str, help='storage logs/models'
--num_workers,      default=4, type=int, help='number of workers to load data'
--resume,           default=None, type=str, help='resume from checkpoint,such as ../output/'
--net,              default='wideresnet', type=str, help='use net '
--gpunum,           default='2', type=int, help='number of gpu , such as 2 '
--parallel,         default='dataparallel', help='way of Parallel,dataparallel or distributed'
```
#### (2)ç”¨æ³•-2
smmg_dist.py ä½¿ç”¨torch.nn.parallel.DistributedDataParallelæ–¹æ³•è¿›è¡Œæ•°æ®åˆ†å¸ƒå¼ã€‚    
```
python smmg_dist.py --gpu_device 0 1 2 3 --batch_size 768  
```
**å‚æ•°è¯´æ˜ï¼š**  
```
--lr              default=0.1, help=''
--resume          default=None, help=''
--batch_size      type=int, default=768, help=''
--num_workers     type=int, default=4, help=''
--gpu_devices     type=int, nargs='+', default=None, help=""

--gpu             default=None, type=int, help='GPU id to use.'
--dist-url        default='tcp://127.0.0.1:3456', type=str, help=''
--dist-backend    default='gloo', type=str, help=''
--rank            default=0, type=int, help=''
--world_size      default=1, type=int, help=''
--distributed     action='store_true', help=''
```
### 5. pytorchæŒ‡å®šæ˜¾å¡çš„å‡ ç§æ–¹å¼   
1.ç›´æ¥ç»ˆç«¯ä¸­è®¾å®šï¼š   
```
CUDA_VISIBLE_DEVICES=1 python my_script.py
```
2.pythonä»£ç ä¸­è®¾å®šï¼š   
```
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "2"
```
3.ä½¿ç”¨å‡½æ•° set_device
```
import torch
torch.cuda.set_device(id)
```
## ä¸‰ã€Dockerç¯å¢ƒæµ‹è¯•
### 1.Dockerç¯å¢ƒå‡†å¤‡
é•œåƒï¼šfusimeng/ai-pytorch:16.04-10.0-3.5-1.1.0   
### 2.æ•°æ®å‡†å¤‡
åŒä¸Š
### 3.ä»£ç å‡†å¤‡
åŒä¸Š
### 4.æµ‹è¯•
  
-----------------------------------------------------------------------   